{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import uuid\n",
    "import os\n",
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8.1\n"
     ]
    }
   ],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Code to show camera frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Video Output', frame)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A fully functional code showing the overlay of fingers on camera output frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Detections\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # # Detections\n",
    "        # print(results)\n",
    "        \n",
    "        # Rendering results\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n",
    "                                        mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=10),\n",
    "                                        mp_drawing.DrawingSpec(color=(198, 44, 250), thickness=2, circle_radius=5),\n",
    "                                         )\n",
    "            \n",
    "        \n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the Landmarks of the hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'mediapipe.python.solutions.hands' from 'c:\\\\Users\\\\kunal\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\mediapipe\\\\python\\\\solutions\\\\hands.py'>\n"
     ]
    }
   ],
   "source": [
    "print(hands) #connected with the previous cell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code which changes the color of the finger tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hand Module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# Custom colors for fingertips\n",
    "finger_tip_colors = [(0, 0, 255),  # Red for thumb\n",
    "                     (0, 255, 0),  # Green for index finger\n",
    "                     (255, 0, 0),  # Blue for middle finger\n",
    "                     (255, 255, 0),  # Yellow for ring finger\n",
    "                     (0, 255, 255)  # Cyan for pinky finger\n",
    "                    ]\n",
    "\n",
    "# Function to get fingertip coordinates for a hand\n",
    "def get_fingertip_coordinates(landmarks):\n",
    "    fingertip_coordinates = []\n",
    "    for idx, landmark in enumerate(landmarks.landmark):\n",
    "        if idx in [4, 8, 12, 16, 20]:  # Indexes for the tips of the five fingers\n",
    "            h, w, c = frame.shape\n",
    "            cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "            fingertip_coordinates.append((cx, cy))\n",
    "    return fingertip_coordinates\n",
    "\n",
    "# Capture Video Stream (or Load Image)\n",
    "cap = cv2.VideoCapture(0)  # 0 for the default webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Read a frame from the webcam\n",
    "\n",
    "    # Convert the BGR frame to RGB (MediaPipe uses RGB format)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame to detect hands\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Get fingertip coordinates for the hand\n",
    "            fingertip_coords = get_fingertip_coordinates(hand_landmarks)\n",
    "\n",
    "            # Draw circles for fingertips with custom colors\n",
    "            for i, coord in enumerate(fingertip_coords):\n",
    "                color = finger_tip_colors[i]\n",
    "                cv2.circle(frame, coord, radius=10, color=color, thickness=-1)  # Draw a filled circle\n",
    "\n",
    "            # Draw hand landmarks\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Display the frame with landmarks\n",
    "    cv2.imshow(\"Hand Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):  # Press Q to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code with detection of gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hand Module\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Custom colors for fingertips\n",
    "finger_tip_colors = [(0, 0, 255),  # Red for thumb\n",
    "                     (0, 255, 0),  # Green for index finger\n",
    "                     (255, 0, 0),  # Blue for middle finger\n",
    "                     (255, 255, 0),  # Yellow for ring finger\n",
    "                     (0, 255, 255)  # Cyan for pinky finger\n",
    "                    ]\n",
    "\n",
    "# Function to get fingertip coordinates for a hand\n",
    "def get_fingertip_coordinates(landmarks):\n",
    "    fingertip_coordinates = []\n",
    "    for idx, landmark in enumerate(landmarks.landmark):\n",
    "        if idx in [4, 8, 12, 16, 20]:  # Indexes for the tips of the five fingers\n",
    "            h, w, c = frame.shape\n",
    "            cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "            fingertip_coordinates.append((cx, cy))\n",
    "    return fingertip_coordinates\n",
    "\n",
    "# Function to detect and print gestures\n",
    "def detect_gestures(landmarks):\n",
    "    # Calculate distances between fingertip landmarks\n",
    "    thumb_tip = landmarks[0]\n",
    "    index_tip = landmarks[1]\n",
    "    middle_tip = landmarks[2]\n",
    "    ring_tip = landmarks[3]\n",
    "    pinky_tip = landmarks[4]\n",
    "\n",
    "    # Calculate Euclidean distances between thumb and other fingertips\n",
    "    distance_to_index = ((thumb_tip[0] - index_tip[0])**2 + (thumb_tip[1] - index_tip[1])**2)**0.5\n",
    "    distance_to_middle = ((thumb_tip[0] - middle_tip[0])**2 + (thumb_tip[1] - middle_tip[1])**2)**0.5\n",
    "    distance_to_ring = ((thumb_tip[0] - ring_tip[0])**2 + (thumb_tip[1] - ring_tip[1])**2)**0.5\n",
    "    distance_to_pinky = ((thumb_tip[0] - pinky_tip[0])**2 + (thumb_tip[1] - pinky_tip[1])**2)**0.5\n",
    "\n",
    "    # Define a threshold for the fist gesture\n",
    "    fist_threshold = 60.0  # Adjust this threshold as needed\n",
    "\n",
    "    # Detect and print gestures\n",
    "    if (distance_to_index < fist_threshold and\n",
    "        distance_to_middle < fist_threshold and\n",
    "        distance_to_ring < fist_threshold and\n",
    "        distance_to_pinky < fist_threshold):\n",
    "        return \"Fist\"\n",
    "    else:\n",
    "        return \"Open Hand\"\n",
    "\n",
    "# Capture Video Stream (or Load Image)\n",
    "cap = cv2.VideoCapture(0)  # 0 for the default webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Read a frame from the webcam\n",
    "\n",
    "    # Convert the BGR frame to RGB (MediaPipe uses RGB format)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame to detect hands\n",
    "    results = hands.process(rgb_frame)\n",
    "    \n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Get fingertip coordinates for the hand\n",
    "            fingertip_coords = get_fingertip_coordinates(hand_landmarks)\n",
    "\n",
    "            # Draw circles for fingertips with custom colors\n",
    "            for i, coord in enumerate(fingertip_coords):\n",
    "                color = finger_tip_colors[i]\n",
    "                cv2.circle(frame, coord, radius=10, color=color, thickness=-1)  # Draw a filled circle\n",
    "\n",
    "            # Detect and print gestures\n",
    "            gesture = detect_gestures(fingertip_coords)\n",
    "            cv2.putText(frame, gesture, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # Draw hand landmarks\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Display the frame with landmarks and gestures after \"RESIZE\"\n",
    "    resize = cv2.resize(frame, (1280, 960))\n",
    "    cv2.imshow(\"Hand Tracking\", resize)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'): # Press Esc to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Curser with Open Hand and stopping with fist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import threading\n",
    "pyautogui.FAILSAFE = False\n",
    "# Initialize MediaPipe Hand Module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "finger_tip_colors = [(0, 0, 255),  # Red for thumb\n",
    "                     (0, 255, 0),  # Green for index finger\n",
    "                     (255, 0, 0),  # Blue for middle finger\n",
    "                     (255, 255, 0),  # Yellow for ring finger\n",
    "                     (0, 255, 255)  # Cyan for pinky finger\n",
    "                    ]\n",
    "# Constants for screen dimensions (adjust as needed)\n",
    "SCREEN_WIDTH = 1920  # Screen width in pixels\n",
    "SCREEN_HEIGHT = 1080  # Screen height in pixels\n",
    "\n",
    "# Function to get fingertip coordinates for a hand\n",
    "def get_fingertip_coordinates(landmarks):\n",
    "    fingertip_coordinates = []\n",
    "    for idx, landmark in enumerate(landmarks.landmark):\n",
    "        if idx in [4, 8, 12, 16, 20]:  # Indexes for the tips of the five fingers\n",
    "            h, w, c = frame.shape\n",
    "            cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "            fingertip_coordinates.append((cx, cy))\n",
    "    return fingertip_coordinates\n",
    "\n",
    "# Function to detect and print gestures\n",
    "def detect_gestures(landmarks):\n",
    "    # Calculate distances between fingertip landmarks\n",
    "    thumb_tip = landmarks[0]\n",
    "    index_tip = landmarks[1]\n",
    "    middle_tip = landmarks[2]\n",
    "    ring_tip = landmarks[3]\n",
    "    pinky_tip = landmarks[4]\n",
    "\n",
    "    # Calculate Euclidean distances between thumb and other fingertips\n",
    "    distance_to_index = ((thumb_tip[0] - index_tip[0])**2 + (thumb_tip[1] - index_tip[1])**2)**0.5\n",
    "    distance_to_middle = ((thumb_tip[0] - middle_tip[0])**2 + (thumb_tip[1] - middle_tip[1])**2)**0.5\n",
    "    distance_to_ring = ((thumb_tip[0] - ring_tip[0])**2 + (thumb_tip[1] - ring_tip[1])**2)**0.5\n",
    "    distance_to_pinky = ((thumb_tip[0] - pinky_tip[0])**2 + (thumb_tip[1] - pinky_tip[1])**2)**0.5\n",
    "\n",
    "    # Define a threshold for the open hand gesture\n",
    "    open_hand_threshold_cm = 80.0  # Adjust this threshold as needed\n",
    "    fist_threshold_cm = 100.0  # Adjust this threshold as needed\n",
    "\n",
    "    # Detect open hand gesture\n",
    "    if (\n",
    "        distance_to_index > open_hand_threshold_cm\n",
    "        and distance_to_middle > open_hand_threshold_cm\n",
    "        and distance_to_ring > open_hand_threshold_cm\n",
    "        and distance_to_pinky > open_hand_threshold_cm\n",
    "    ):\n",
    "        return \"Open Hand\"\n",
    "    # Detect fist gesture\n",
    "    elif (\n",
    "        distance_to_index < fist_threshold_cm\n",
    "        and distance_to_middle < fist_threshold_cm\n",
    "        and distance_to_ring < fist_threshold_cm\n",
    "        and distance_to_pinky < fist_threshold_cm\n",
    "    ):\n",
    "        return \"Fist\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Function to control the mouse cursor relative to the screen\n",
    "def control_mouse(fingertip_coords, last_cursor_position):\n",
    "    if len(fingertip_coords) > 0:\n",
    "        x, y = pyautogui.position()  # Get the current mouse position\n",
    "        speed = 30  # Adjust the speed as needed\n",
    "        movement_distance_cm = 4.0  # Adjust the desired movement distance in centimeters\n",
    "        movement_distance_px = (movement_distance_cm / SCREEN_WIDTH) * SCREEN_WIDTH\n",
    "        dx = fingertip_coords[0][0] - last_cursor_position[0]\n",
    "        dy = fingertip_coords[0][1] - last_cursor_position[1]\n",
    "        pyautogui.moveRel(dx * movement_distance_px, dy * movement_distance_px, duration=0.1 / speed)\n",
    "        return (fingertip_coords[0][0], fingertip_coords[0][1])\n",
    "    return last_cursor_position\n",
    "\n",
    "# Capture Video Stream (or Load Image)\n",
    "cap = cv2.VideoCapture(0)  # 0 for the default webcam\n",
    "\n",
    "# Initialize the cursor position\n",
    "cursor_position = (SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Read a frame from the webcam\n",
    "    # image = cv2.flip(image, 1)\n",
    "    # Convert the BGR frame to RGB (MediaPipe uses RGB format)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame to detect hands\n",
    "    results = hands.process(rgb_frame)\n",
    "    close=0\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Get fingertip coordinates for the hand\n",
    "            fingertip_coords = get_fingertip_coordinates(hand_landmarks)\n",
    "\n",
    "            # Draw circles for fingertips with custom colors\n",
    "            for i, coord in enumerate(fingertip_coords):\n",
    "                color = finger_tip_colors[i]\n",
    "                cv2.circle(frame, coord, radius=10, color=color, thickness=-1)  # Draw a filled circle\n",
    "\n",
    "            # Detect and print gestures\n",
    "            gesture = detect_gestures(fingertip_coords)\n",
    "            cv2.putText(frame, gesture, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # Control the mouse cursor based on the open hand gesture (in a separate thread)\n",
    "            if gesture == \"Open Hand\":\n",
    "                cursor_position = control_mouse(fingertip_coords, cursor_position)\n",
    "            if gesture == \"Fist\":\n",
    "                # pyautogui.click()\n",
    "\n",
    "                close=1\n",
    "                break\n",
    "\n",
    "            # Draw hand landmarks\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "        if close==1:\n",
    "            break\n",
    "    if close==1:\n",
    "        break\n",
    "\n",
    "\n",
    "    # Display the frame with landmarks and gestures\n",
    "    # image = cv2.flip(image, 1)\n",
    "    cv2.imshow(\"Hand Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Press Esc to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Added Scrolling functionality using Index fingers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import threading\n",
    "pyautogui.FAILSAFE = False\n",
    "# Initialize MediaPipe Hand Module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "finger_tip_colors = [(0, 0, 255),  # Red for thumb\n",
    "                     (0, 255, 0),  # Green for index finger\n",
    "                     (255, 0, 0),  # Blue for middle finger\n",
    "                     (255, 255, 0),  # Yellow for ring finger\n",
    "                     (0, 255, 255)  # Cyan for pinky finger\n",
    "                    ]\n",
    "# Constants for screen dimensions (adjust as needed)\n",
    "SCREEN_WIDTH = 1920  # Screen width in pixels\n",
    "SCREEN_HEIGHT = 1080  # Screen height in pixels\n",
    "SCROLL_SPEED = 20  # Adjust the scroll speed as needed\n",
    "SCROLL_THRESHOLD = 100  # Adjust the scroll threshold as needed\n",
    "# Function to get fingertip coordinates for a hand\n",
    "def get_fingertip_coordinates(landmarks):\n",
    "    fingertip_coordinates = []\n",
    "    for idx, landmark in enumerate(landmarks.landmark):\n",
    "        if idx in [4, 8, 12, 16, 20]:  # Indexes for the tips of the five fingers\n",
    "            h, w, c = frame.shape\n",
    "            cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "            fingertip_coordinates.append((cx, cy))\n",
    "    return fingertip_coordinates\n",
    "\n",
    "# Function to detect and print gestures\n",
    "def detect_gestures(landmarks):\n",
    "    # Calculate distances between fingertip landmarks\n",
    "    thumb_tip = landmarks[0]\n",
    "    index_tip = landmarks[1]\n",
    "    middle_tip = landmarks[2]\n",
    "    ring_tip = landmarks[3]\n",
    "    pinky_tip = landmarks[4]\n",
    "\n",
    "    # Calculate Euclidean distances between thumb and other fingertips\n",
    "    distance_to_index = ((thumb_tip[0] - index_tip[0])**2 + (thumb_tip[1] - index_tip[1])**2)**0.5\n",
    "    distance_to_middle = ((thumb_tip[0] - middle_tip[0])**2 + (thumb_tip[1] - middle_tip[1])**2)**0.5\n",
    "    distance_to_ring = ((thumb_tip[0] - ring_tip[0])**2 + (thumb_tip[1] - ring_tip[1])**2)**0.5\n",
    "    distance_to_pinky = ((thumb_tip[0] - pinky_tip[0])**2 + (thumb_tip[1] - pinky_tip[1])**2)**0.5\n",
    "\n",
    "    # Define a threshold for the open hand gesture\n",
    "    open_hand_threshold_cm = 50.0  # Adjust this threshold as needed\n",
    "    fist_threshold_cm = 50.0  # Adjust this threshold as needed\n",
    "\n",
    "    # Detect open hand gesture\n",
    "    if (\n",
    "        distance_to_index > open_hand_threshold_cm\n",
    "        and distance_to_middle > open_hand_threshold_cm\n",
    "        and distance_to_ring > open_hand_threshold_cm\n",
    "        and distance_to_pinky > open_hand_threshold_cm\n",
    "    ):\n",
    "        return \"Open Hand\"\n",
    "    # Detect fist gesture\n",
    "    elif (\n",
    "        distance_to_index < fist_threshold_cm\n",
    "        and distance_to_middle < fist_threshold_cm\n",
    "        and distance_to_ring < fist_threshold_cm\n",
    "        and distance_to_pinky < fist_threshold_cm\n",
    "    ):\n",
    "        return \"Fist\"\n",
    "    # Get the y-coordinate of the index fingertip\n",
    "    index_fingertip_y = landmarks[0][1] if len(landmarks) > 0 else None\n",
    "\n",
    "    # Initialize previous fingertip y-coordinate\n",
    "    if \"prev_y\" not in detect_gestures.__dict__:\n",
    "        detect_gestures.prev_y = index_fingertip_y\n",
    "\n",
    "    # Calculate the difference in y-coordinate\n",
    "    y_difference = index_fingertip_y - detect_gestures.prev_y\n",
    "    detect_gestures.prev_y = index_fingertip_y\n",
    "\n",
    "    # Detect scrolling gestures\n",
    "    if y_difference > SCROLL_THRESHOLD:\n",
    "        return \"Scroll Down\"\n",
    "    elif y_difference < -SCROLL_THRESHOLD:\n",
    "        return \"Scroll Up\"\n",
    "\n",
    "    return \"Neutral\"\n",
    "def perform_scroll(gesture):\n",
    "    if gesture == \"Scroll Up\":\n",
    "        pyautogui.scroll(SCROLL_SPEED)\n",
    "    elif gesture == \"Scroll Down\":\n",
    "        pyautogui.scroll(-SCROLL_SPEED)\n",
    "\n",
    "# Function to control the mouse cursor relative to the screen\n",
    "def control_mouse(fingertip_coords, last_cursor_position):\n",
    "    if len(fingertip_coords) > 0:\n",
    "        x, y = pyautogui.position()  # Get the current mouse position\n",
    "        speed = 30  # Adjust the speed as needed\n",
    "        movement_distance_cm = 4.0  # Adjust the desired movement distance in centimeters\n",
    "        movement_distance_px = (movement_distance_cm / SCREEN_WIDTH) * SCREEN_WIDTH\n",
    "        dx = fingertip_coords[0][0] - last_cursor_position[0]\n",
    "        dy = fingertip_coords[0][1] - last_cursor_position[1]\n",
    "        pyautogui.moveRel(dx * movement_distance_px, dy * movement_distance_px, duration=0.1 / speed)\n",
    "        return (fingertip_coords[0][0], fingertip_coords[0][1])\n",
    "    return last_cursor_position\n",
    "\n",
    "# Capture Video Stream (or Load Image)\n",
    "cap = cv2.VideoCapture(0)  # 0 for the default webcam\n",
    "\n",
    "# Initialize the cursor position\n",
    "cursor_position = (SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Read a frame from the webcam\n",
    "    # image = cv2.flip(image, 1)\n",
    "    # Convert the BGR frame to RGB (MediaPipe uses RGB format)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame to detect hands\n",
    "    results = hands.process(rgb_frame)\n",
    "    close=0\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Get fingertip coordinates for the hand\n",
    "            fingertip_coords = get_fingertip_coordinates(hand_landmarks)\n",
    "\n",
    "            # Draw circles for fingertips with custom colors\n",
    "            for i, coord in enumerate(fingertip_coords):\n",
    "                color = finger_tip_colors[i]\n",
    "                cv2.circle(frame, coord, radius=10, color=color, thickness=-1)  # Draw a filled circle\n",
    "\n",
    "            # Detect and print gestures\n",
    "            gesture = detect_gestures(fingertip_coords)\n",
    "            cv2.putText(frame, gesture, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # Control the mouse cursor based on the open hand gesture (in a separate thread)\n",
    "            # Perform scrolling based on gestures\n",
    "            if gesture==\"Scroll Down\" or gesture==\"Scroll Up\":\n",
    "                perform_scroll(gesture)\n",
    "            if gesture == \"Open Hand\":\n",
    "                cursor_position = control_mouse(fingertip_coords, cursor_position)\n",
    "            # if gesture == \"Fist\":\n",
    "            #     pyautogui.click()\n",
    "\n",
    "            # Draw hand landmarks\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Display the frame with landmarks and gestures\n",
    "    # image = cv2.flip(image, 1)\n",
    "    cv2.imshow(\"Hand Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Press Esc to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrolling using index finger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "# Disable PyAutoGUI fail-safe\n",
    "pyautogui.FAILSAFE = False\n",
    "\n",
    "# Initialize MediaPipe Hand Module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Constants for screen dimensions (adjust as needed)\n",
    "SCREEN_WIDTH = 1920  # Screen width in pixels\n",
    "SCREEN_HEIGHT = 1080  # Screen height in pixels\n",
    "\n",
    "# Function to get fingertip coordinates for a hand\n",
    "def get_fingertip_coordinates(landmarks):\n",
    "    fingertip_coordinates = []\n",
    "    for idx, landmark in enumerate(landmarks.landmark):\n",
    "        if idx == 8:  # Index for the tip of the index finger\n",
    "            h, w, c = frame.shape\n",
    "            cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "            fingertip_coordinates.append((cx, cy))\n",
    "    return fingertip_coordinates\n",
    "\n",
    "# Function to control the cursor based on finger movement\n",
    "def control_cursor(fingertip_coords, last_cursor_position):\n",
    "    if len(fingertip_coords) > 0:\n",
    "        x, y = pyautogui.position()  # Get the current cursor position\n",
    "        speed = 20  # Adjust the speed as needed\n",
    "        movement_distance_cm = 5.0  # Adjust the desired movement distance in centimeters\n",
    "        movement_distance_px = (movement_distance_cm / SCREEN_WIDTH) * SCREEN_WIDTH\n",
    "        dx = fingertip_coords[0][0] - last_cursor_position[0]\n",
    "        dy = fingertip_coords[0][1] - last_cursor_position[1]\n",
    "        pyautogui.moveRel(dx * movement_distance_px, dy * movement_distance_px, duration=0.1 / speed)\n",
    "        return (fingertip_coords[0][0], fingertip_coords[0][1])\n",
    "    return last_cursor_position\n",
    "\n",
    "# Capture Video Stream (or Load Image)\n",
    "cap = cv2.VideoCapture(0)  # 0 for the default webcam\n",
    "\n",
    "# Initialize the cursor position\n",
    "cursor_position = (SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Read a frame from the webcam\n",
    "    frame=cv2.flip(frame,1)\n",
    "\n",
    "    # Convert the BGR frame to RGB (MediaPipe uses RGB format)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame to detect hands\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Get fingertip coordinates for the hand\n",
    "            fingertip_coords = get_fingertip_coordinates(hand_landmarks)\n",
    "\n",
    "            # Draw a circle for the index fingertip\n",
    "            if fingertip_coords:\n",
    "                cv2.circle(frame, fingertip_coords[0], radius=10, color=(0, 255, 0), thickness=-1)  # Green circle\n",
    "\n",
    "                # Control the cursor based on finger movement\n",
    "                cursor_position = control_cursor(fingertip_coords, cursor_position)\n",
    "\n",
    "            # Draw hand landmarks\n",
    "            mp.solutions.drawing_utils.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Display the frame with landmarks and cursor movement\n",
    "    cv2.imshow(\"Hand Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Press Esc to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving cursor with index finger and clicking by folding middle finger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import math\n",
    "\n",
    "# Disable PyAutoGUI fail-safe\n",
    "pyautogui.FAILSAFE = False\n",
    "\n",
    "# Initialize MediaPipe Hand Module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Constants for screen dimensions (adjust as needed)\n",
    "SCREEN_WIDTH = 1920  # Screen width in pixels\n",
    "SCREEN_HEIGHT = 1080  # Screen height in pixels\n",
    "prev_fingertip_coords = None\n",
    "# Constants for cursor movement smoothing\n",
    "# SMOOTHING_FACTOR = 0.2  Adjust the smoothing factor (0.0 to 1.0) as needed\n",
    "\n",
    "# Variables to track cursor position and velocity\n",
    "cursor_position = (SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2)\n",
    "cursor_velocity = [0, 0]\n",
    "\n",
    "# Custom colors for fingertips\n",
    "finger_tip_colors = [(0, 0, 255),  # Red for thumb\n",
    "                     (0, 255, 0),  # Green for index finger\n",
    "                     (255, 0, 0),  # Blue for middle finger\n",
    "                     (255, 255, 0),  # Yellow for ring finger\n",
    "                     (0, 255, 255)  # Cyan for pinky finger\n",
    "                    ]\n",
    "\n",
    "# Function to get fingertip coordinates for a hand\n",
    "def get_fingertip_coordinates(landmarks):\n",
    "    fingertip_coordinates = []\n",
    "    for idx, landmark in enumerate(landmarks.landmark):\n",
    "        if idx ==8:  # Indexes for the tips of the five fingers\n",
    "            h, w, c = frame.shape\n",
    "            cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "            fingertip_coordinates.append((cx, cy))\n",
    "    return fingertip_coordinates\n",
    "\n",
    " \n",
    "# Function to control the cursor based on finger movement\n",
    "movement_distance_cm = 9.0  # Adjust this value as needed\n",
    "# ... (previous code)\n",
    "\n",
    "# Variables for low-pass filtering\n",
    "filter_alpha = 1.0  # Smoothing factor (0.0 to 1.0)\n",
    "# ... (previous code)\n",
    "\n",
    "# Function to get distance between two points\n",
    "def calculate_distance(point1, point2):\n",
    "    return ((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2) ** 0.5\n",
    "\n",
    "# ... (previous code)\n",
    "\n",
    "# Function to check if the middle finger is folded\n",
    "def calculate_angle(l1, l2, l3):\n",
    "    x1, y1 = l1.x, l1.y\n",
    "    x2, y2 = l2.x, l2.y\n",
    "    x3, y3 = l3.x, l3.y\n",
    "\n",
    "    # Calculate the vectors between the landmarks\n",
    "    vec1 = (x1 - x2, y1 - y2)\n",
    "    vec2 = (x3 - x2, y3 - y2)\n",
    "\n",
    "    # Calculate the dot product and the magnitudes of the vectors\n",
    "    dot_product = vec1[0] * vec2[0] + vec1[1] * vec2[1]\n",
    "    magnitude1 = (vec1[0] ** 2 + vec1[1] ** 2) ** 0.5\n",
    "    magnitude2 = (vec2[0] ** 2 + vec2[1] ** 2) ** 0.5\n",
    "\n",
    "    # Calculate the angle in degrees\n",
    "    angle_rad = math.acos(dot_product / (magnitude1 * magnitude2))\n",
    "    angle_deg = math.degrees(angle_rad)\n",
    "\n",
    "    return angle_deg\n",
    "def is_middle_finger_folded(hand_landmarks):\n",
    "    # Get the landmarks of the middle finger\n",
    "    middle_finger_landmarks = [\n",
    "        hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP],\n",
    "        hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_PIP],\n",
    "        hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_DIP],\n",
    "        hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "    ]\n",
    "\n",
    "    # Calculate the angle between the finger joints\n",
    "    angle1 = calculate_angle(middle_finger_landmarks[0], middle_finger_landmarks[1], middle_finger_landmarks[2])\n",
    "\n",
    "    # Define a threshold angle (adjust as needed)\n",
    "    threshold_angle = 90.0  # Adjust this value to control the sensitivity\n",
    "\n",
    "    # Check if the middle finger is folded (angle is less than the threshold)\n",
    "    return angle1 < threshold_angle\n",
    "\n",
    "    # Check if the middle finger is folded\n",
    "    return all(angle < 0 for angle in angles)\n",
    "\n",
    "# Function to control cursor movement and click\n",
    "def control_cursor_and_click(fingertip_coords, hand_landmarks):\n",
    "    global cursor_position, cursor_velocity, prev_fingertip_coords\n",
    "\n",
    "    if len(fingertip_coords) >= 1:\n",
    "        # Check if the middle finger is folded\n",
    "        if is_middle_finger_folded(hand_landmarks):\n",
    "            pyautogui.click()  # Execute a click action\n",
    "        else:\n",
    "            # Move the cursor with the index finger\n",
    "            if prev_fingertip_coords is not None:\n",
    "                dx = fingertip_coords[0][0] - prev_fingertip_coords[0][0]\n",
    "                dy = fingertip_coords[0][1] - prev_fingertip_coords[0][1]\n",
    "\n",
    "                movement_x = dx * movement_distance_cm * SCREEN_WIDTH / 1920\n",
    "                movement_y = dy * movement_distance_cm * SCREEN_HEIGHT / 1080\n",
    "\n",
    "                cursor_velocity = (\n",
    "                    filter_alpha * movement_x + (1 - filter_alpha) * cursor_velocity[0],\n",
    "                    filter_alpha * movement_y + (1 - filter_alpha) * cursor_velocity[1],\n",
    "                )\n",
    "\n",
    "                cursor_position = (\n",
    "                    cursor_position[0] + int(cursor_velocity[0]),\n",
    "                    cursor_position[1] + int(cursor_velocity[1]),\n",
    "                )\n",
    "\n",
    "                cursor_position = (\n",
    "                    min(max(cursor_position[0], 0), SCREEN_WIDTH),\n",
    "                    min(max(cursor_position[1], 0), SCREEN_HEIGHT),\n",
    "                )\n",
    "\n",
    "                pyautogui.moveTo(cursor_position[0], cursor_position[1])\n",
    "\n",
    "        prev_fingertip_coords = fingertip_coords\n",
    "    else:\n",
    "        prev_fingertip_coords = None\n",
    "\n",
    "# Capture Video Stream (or Load Image)\n",
    "cap = cv2.VideoCapture(0)  # 0 for the default webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Read a frame from the webcam\n",
    "    frame=cv2.flip(frame,1)\n",
    "    # Convert the BGR frame to RGB (MediaPipe uses RGB format)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame to detect hands\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Get fingertip coordinates for the hand\n",
    "            fingertip_coords = get_fingertip_coordinates(hand_landmarks)\n",
    "\n",
    "            # Draw circles for fingertips with custom colors\n",
    "            for i, coord in enumerate(fingertip_coords):\n",
    "                color = finger_tip_colors[i]\n",
    "                cv2.circle(frame, coord, radius=10, color=color, thickness=-1)  # Draw a filled circle\n",
    "            \n",
    "                # Control the cursor based on finger movement\n",
    "                control_cursor_and_click(fingertip_coords, hand_landmarks)\n",
    "            if is_middle_finger_folded(hand_landmarks):\n",
    "                    cv2.putText(frame, \"Middle Finger Folded\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # Draw hand landmarks\n",
    "            mp.solutions.drawing_utils.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Display the frame with landmarks and smoothed cursor movement\n",
    "    cv2.imshow(\"Hand Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Press Esc to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynput.keyboard import Key, Controller as KeyboardController\n",
    "from pynput.mouse import  Controller as MouseController\n",
    "\n",
    "mouse = MouseController()\n",
    "keyboard=KeyboardController()\n",
    "\n",
    "k=int(input(\"enter number\"))\n",
    "if k==1:\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
