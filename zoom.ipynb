{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from pynput.mouse import Button,Controller as MouseController\n",
    "from pynput.keyboard import Key,Controller as KeyboardController\n",
    "import pyautogui\n",
    "import time\n",
    "mouse=MouseController()\n",
    "keyboard=KeyboardController()\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "def zoom_in():\n",
    "    # Simulate pressing the 'Ctrl' key and the '+' key to zoom in (browser example)\n",
    "    pyautogui.hotkey('ctrl', '+')\n",
    "    time.sleep(0.5)\n",
    "\n",
    "def zoom_out():\n",
    "    # Simulate pressing the 'Ctrl' key and the '-' key to zoom out (browser example)\n",
    "    with keyboard.pressed(Key.ctrl_l):\n",
    "        keyboard.press('-')\n",
    "        keyboard.release('-')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "def detect_touching(landmarks):\n",
    "    finger_landmarks = landmarks.landmark\n",
    "\n",
    "    # Define landmarks for thumb, index, middle, ring, and pinky fingers\n",
    "    thumb_tip_id = 4\n",
    "    index_tip_id = 8\n",
    "    middle_tip_id = 12\n",
    "    ring_tip_id = 16\n",
    "    pinky_tip_id = 20\n",
    "\n",
    "    if len(finger_landmarks) >= 21:  # Check if enough landmarks are detected\n",
    "        thumb_tip = np.array([finger_landmarks[thumb_tip_id].x, finger_landmarks[thumb_tip_id].y])\n",
    "        index_tip = np.array([finger_landmarks[index_tip_id].x, finger_landmarks[index_tip_id].y])\n",
    "        middle_tip = np.array([finger_landmarks[middle_tip_id].x, finger_landmarks[middle_tip_id].y])\n",
    "        ring_tip = np.array([finger_landmarks[ring_tip_id].x, finger_landmarks[ring_tip_id].y])\n",
    "        pinky_tip = np.array([finger_landmarks[pinky_tip_id].x, finger_landmarks[pinky_tip_id].y])\n",
    "\n",
    "        # Define a distance threshold for considering fingers as touching\n",
    "        distance_threshold = 0.05  # Adjust this threshold as needed\n",
    "\n",
    "        # Calculate the Euclidean distance between thumb and fingers\n",
    "        index_distance = np.linalg.norm(thumb_tip - index_tip)\n",
    "        middle_distance = np.linalg.norm(thumb_tip - middle_tip)\n",
    "        ring_distance = np.linalg.norm(thumb_tip - ring_tip)\n",
    "        pinky_distance = np.linalg.norm(thumb_tip - pinky_tip)\n",
    "\n",
    "        # Check if any finger is touching\n",
    "        if index_distance < distance_threshold:\n",
    "            return 'index'\n",
    "        elif middle_distance < distance_threshold:\n",
    "            return 'middle'\n",
    "        elif ring_distance < distance_threshold:\n",
    "            return 'ring'\n",
    "        elif pinky_distance < distance_threshold:\n",
    "            return 'pinky'\n",
    "\n",
    "    return None\n",
    "# Set the frame size to 1280x720 (720p)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        # Flip the frame horizontally\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert the BGR image to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the frame and detect hands\n",
    "        results = hands.process(frame_rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for landmarks in results.multi_hand_landmarks:\n",
    "                # Detect if any of the fingers touch the thumb\n",
    "                touching_finger = detect_touching(landmarks)\n",
    "\n",
    "                if touching_finger == 'index':\n",
    "                    cv2.putText(frame, 'Index Touching', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                elif touching_finger == 'middle':\n",
    "                    cv2.putText(frame, 'Middle Touching', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                elif touching_finger == 'ring':\n",
    "                    cv2.putText(frame, 'Ring Touching', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    zoom_in()\n",
    "                elif touching_finger == 'pinky':\n",
    "                    cv2.putText(frame, 'Pinky Touching', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    zoom_out()\n",
    "\n",
    "        cv2.imshow('Hand Tracking', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Press 'Esc' to exit\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
